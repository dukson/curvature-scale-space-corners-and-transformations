Lacking an app to keep these in, making a temporary file while
implementing...

=====================================================================
Story: Near optimization of SkylineExtractor's findClouds method.
 
    summary: findClouds needs to be changed to make it possible to
      find the best fitting or nearly best fitting combinations
      of color and contrast clauses.  The clauses are the conditional
      logic to learn whether a pixel is sky or not and hence added
      to the sky points (or not) in a BFS visitor pattern.
      
      findClouds is currently given a set of seed sky points
      and the original color image and gradient images from which
      it applies various color and contrast clauses to grow the
      seed sky points until they reach the skyline or close to the
      skyline.  
      findClouds needs to be refactored to also accept as arguments,
      the clauses and coefficients for the clauses.
      The SkylineExtractor may need additional changes to make sure
      that member variables don't change state upon running findClouds
      so it can be re-used with the same images and a fresh set of
      sky points, clauses, and clause coefficients.

      A fitness function is needed to estimate how close the result
      is to the expected result.
         This involves defining the skyline and sky points accurately
      for the tests.  The penalty for overrunning the skyline boundary
      should be very large.

      An algorithm is needed to use the fitness function to determine
      the next set of improved coefficients to be tried w/ findClouds.
      Because there are so many parameters, a gradient approach is 
      less appealing than a heuristic approach such as the 
      Nelder-Mead downhill simplex method, so will use that.

      A harness that accepts image files and runs the findClouds
      method over all of the possible combinations of clauses,
      called equations and uses the downhill simplex method to
      find the nearly best fitting or best fitting coefficients
      for each equation and test image is needed.

      A pattern of determining the best fitting coefficients 
      among each equation and test is needed within the harness.

      A means of making the expected results for the test images is
      needed.

    possible complications: 
       unknown existing bugs found in the process that may need to
          be fixed (usually not a problem, but have delayed better
          testing habits while exploring how to implement most of 
          this and related code.)
       some test images not yet included will require a change in 
          the methods preceding the use of findClouds to find the
          sky seed points.  those images are not included and the
          method doesn't exist yet, but the images could be included
          with guesstimated seed sky points given to findClouds 
          (but this would not be a robust long term solution).

      notes still in todo.txt should be moved here to create targets...

    time estimate: 
        minimum: 
        maximum: 

    amount of time used: 

    state of completion: The story is complete, but is not optimized
        and may need to be re-opened with new test data in the future.

    comments regarding state:  The story is complete, but is not optimized
        and may need to be re-opened with new test data in the future.

    comments:

---------------------------------------------------------------------
Task 1:
    goal: Create the expected sky-only masks from the test images to
          compare the results with.

    details:  
          This could be done by starting with the thresholding part of
          the SkylineExtractor algorithm and then correcting for binning
          and manually extracting the skyline to make a mask using a 
          tool like Gimp.

          requires making a class in tests directory to use the needed
          part of SkylineExtractor and read in and write images.

          Also needs a run target in the build script to run the class,
          but not as a regular part of tests.

   time estimate: 
       15 min + (16 * 15 min).  minimum = 4 hours, maximum 8 hours
  
   amount of time used:
       1 day

   state of completion: complete

   comments:
      re-opened to make very detailed corrections
              
---------------------------------------------------------------------
Task 2:
   goal:  Explore the parameters to be fit to identify the border.
          Use LDA to find the best separability and to see if there
          is a multiplicative relationship between variables.

   details:  
          For the skyline, making 2 sets of data points: those
          about 3 pixels above the skyline and those 1 pixel below
          in order to look at the contrast and color of
          the sky versus non-sky pixels.
          Note that the test image do not have images with sky at
          the bottom and foreground on the top of the image, so using
          the general y-3 and y+1 is fine.

          Parameters that appear to be the strongest changing at the
          skyline are contrast, hue and blue or red depending on
          whether the sky is blue or red.

          The properties to explore are constructed similarly to how 
          they are constructed during the growing of pixels in findClouds.
          For a sky pixel in which a neighbor is being tested for
          contrast and color which indicates that it is also sky
          or is a border skyline pixel, the property tested for 
          contrast is 
          ((average contrast of its neighbor sky pixels) 
              - (contrast of candidate pixel)) /
              (standard deviation of contrast in the neighbor sky pixels)
          where neighbors is defined as the surrounding 8 sky pixels or 
          surrounding 24.

   time estimate: roughly max of 2 days.
  
   amount of time used:
       2 days

   state of completion: complete

   comments:
       LDA shows that neither the blue nor the red are separable by
       the chosen features as a single global filter to apply to either
       any red sky image or any blue sky image.

       One can see in the images that there is a jump in contrast and
       in blue or red depending on sky color at the boundary of the
       skyline, but the amount of change in the contrast or color is
       not easily seen as a single constant coefficient times other 
       properties.  That's understandable as the sky illumination 
       from the sun and the subsequent color dependent illumination 
       of the foreground horizon is not a simple function of intensity 
       (or even exponential of the intensity or power of the intensity 
       because of multiple scatterings and the albedo (index of 
       refraction) of the foreground skyline).

       Therefore, the existing approach and its refinement in Task 3
       is the better way to proceed, though this can be revisited when
       refined features have been derived.

------------------------------------------------------------------------
Task 3:
    goal: Design the passing and use of the clause coefficients and 
       clauses.

    details:  
       findClouds needs to accept as arguments the coefficients of
       clauses and the clauses. 
       A complete clause can be:
           ((param1/param2)  LTorGT coeff)  where param2 can be a '1'

       It also needs a way of knowing that param1 is color_point - color_sky,
       for example.  the parameter number and the intended parameters
       will be hard wired into the method and documented.

       The logic needed should be possible as ANDs of the clauses, but
       there may be an OR needed for blue and red skies, for example, or
       cluster of logic to create filters.
    
       note that this isn't a constraint satisfaction problem because 
       the coefficients need to be determined and refined.

       A group of AND logic statements are set into an instance of the class:
       ANDedClauses:
          SKYCONDITIONAL[] skyConditional
          PARAM[] param1
          PARAM[] param2
          COMPARISON[] comp
          float[] coefficients
       representing for example:
          (((param1[i]/param2[i]) lt or gt coeff[i]) 
              && ((param1[i+1]/param2[i+1]) lt or gt coeff[i+1]))

       Then the adapted findClouds2 should ue disjunctive normal form logic to
       process the ANDedClauses[] from an array as 'OR's.

       The summary looks like this:
           if (is border pix)
               break
           else if (is border pix)
               break
           else if (is border pix)
               break
           a pixel making it to here looks like a sky pixel

    time estimate: max 2 days
  
    amount of time used: 2 + days 

    state of completion: complete

    comments:
        this in combination with Task 4 showed that custom coeeficients
        were needed fo some clauses.
              
---------------------------------------------------------------------
Task 4:
    goal: implement the overloaded findClouds that accepts the clauses
          and coefficients.

    details:  
          copy findClouds to adapt the method to use the given clauses 
          and coefficients.

          write a simple test for the new method.

   time estimate: (unestimated)
  
   amount of time used: 2 days

   state of completion: complete

   comments:
       An overloaded findClouds accepting the clause has been implemented
       and produces results very close to the original findClouds()
       and should be a set of coefficients that is possible to fit and 
       improve in Task 6.
        
---------------------------------------------------------------------
Task 5:
    goal: write the fitness function that evaluates the result of
          findClouds() by comparison with points for the test image's
          sky mask.

    details:  
        (1) write the fitness function that evaluates the resulting
            sky points from findClouds(clauses) for a test image 
            and compares that to the test image mask points.
            -- there should be a high penalty for overrunning the
               boundary by including non-sky points and the
               subsequent comparison should be for the highest frction
               of matches to expected.
            ==> this function should be written and tested

        Need to make decisions about the embedded non-sky points
           -- not necessarily concerned about fitting for these
              because they may be mostly clouds that are better
              recognized in a subsequent step (embedded pixels which
              look like clouds).
           -- the masks already remove those.  
              -- so the results from findClouds have to have
                 a following step which includes the embedded points.
           -- then the algorithm is completely focused on fitting the
              boundary.  It can be changed later if it's found that
              it's necessary to consider embedded points and gaps
              similarly.  would need to alter the test masks for that
              and add more test images.  that would be another task...

        Then the comparison of expected sky points (these are given
            by the masks) can be directly compared to the
            results of findClouds() + add emebedded.

            Need to keep 2 characteristics to evaluate them:
               keep:  -- the number of points overrunning the boundary divided by the
                         total number of expecte sky points.
               keep:  -- the number of points matched divided by the total number expected.

            comparison:
               better is smaller number of normalized overrun points
               ties and zero are then evaluated:
                   better is higher normalized number of matches to expected. 

        The comparison point sets:
            have from test sky mask:
                Set<PairInt> expectedSkyPoints = readSkyPixels(skyMask);
            have from test image findClouds results:
                Set<PairInt> skyPoints 
                ...
                // find embedded points
                PerimeterFinder perimeterFinder = new PerimeterFinder();
                int[] skyRowMinMax = new int[2];
                Set<PairInt> embeddedPoints = new HashSet<PairInt>();
                Map<Integer, List<PairInt>> skyRowColRange = perimeterFinder.find(
                    points, skyRowMinMax, originalColorImage.getWidth(), 
                    embeddedPoints);

   time estimate: minimum half day, maximum 2 days
  
   amount of time used:

   state of completion: complete

   comments:
              
---------------------------------------------------------------------
Task 6:
    goal: implement the harness to run findClouds over multiple images
        for all equations and return the best fitting coefficients.

    details:  
        (1) Write a general downhill simplex for handling an array 
            of coefficients and an array of suggested step sizes 
            and possibly 2 arrays of boundaries for each 
            coefficient.
            ==> Test the downhill simplex.
                The downhill simplex starter points are most important
                for good results.  for problems that are not actually
                local search, the starter points help provide a rough
                range search from which the remaining algorithm
                can then find improved coefficients.
                so testing has to focus on creating the starter points
                using the given boundaries, and the algorithm's use of
                step size has to be learned by testing too.
                -- presumably, will need to use real test images on 
                  this rather than making simpler test images.
               -- the test results should show that the simplex
                  run on any test image from current set of coefficients
                  results in improved coefficients where improved is
                  evaluated by the fitness function mentioned above.
        (2) Create the method that is a wrapper for using the heuristics
            to improve the coefficients. need to operate on all 
            images as a set to get their individual fitness function
            results and use the totals of those to let the
            downhill simplex improve the coefficients.

   time estimate: 
  
   amount of time used:

   state of completion:
       the harness is implemented and leads to a result at least as
       good as the start.  

   comments:
       a better implementation may be needed one day that is far more 
       complex but has ability to improve automatically.  That impl
       might build successive filter clauses upon need, starting with
       the simplest, and may need to use range searches instead of
       only downhill simplex to find best local results, and may need
       to determine best step sizes.  for some of the filters, for
       example the constrast and color difference filters, an optimization 
       algorithm that uses gradient descent may be possible,
       but even those two (contrast and color diff) have different 
       implicit factors for each image
       (which is not surprising becausing the underlying reason for the
       contrast is lighting upon the foreground object combined with
       the foreground object's index of refraction, albedo, etc.)
       A truly better model may need to pre-prepare sky and cloud illumation
       models (maybe even as patches of sky) and attempt to use information 
       about sun location when available.  To use such a model also 
       requires an interpretation
       of whether snow or water is in the image.  
       Approximating the light source from this information at every point
       that one needs to test foreground pixels is expensive and indeterminate
       due to multiple scattering being the usual case (unless sunset 
       conditions are present).
              
---------------------------------------------------------------------
Task 7:
   goal: find more test images, especially those described as current
          caveats that would need an alternate way of finding the seed
          sky points.

   details:  

   time estimate: 
  
   amount of time used:

   state of completion: complete for now, but should be reopened upon need.

   comments:
              
